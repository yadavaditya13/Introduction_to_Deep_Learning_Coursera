{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generating names with recurrent neural networks\n",
    "\n",
    "This time you'll find yourself delving into the heart (and other intestines) of recurrent neural networks on a class of toy problems.\n",
    "\n",
    "Struggle to find a name for the variable? Let's see how you'll come up with a name for your son/daughter. Surely no human has expertize over what is a good child name, so let us train RNN instead;\n",
    "\n",
    "It's dangerous to go alone, take these:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-08-13T20:26:42.696201Z",
     "start_time": "2018-08-13T20:26:38.104103Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.2.1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "print(tf.__version__)\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import os\n",
    "import sys\n",
    "sys.path.append(\"..\")\n",
    "import keras_utils\n",
    "import tqdm_utils"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load data\n",
    "The dataset contains ~8k earthling names from different cultures, all in latin transcript.\n",
    "\n",
    "This notebook has been designed so as to allow you to quickly swap names for something similar: deep learning article titles, IKEA furniture, pokemon names, etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-08-13T20:26:42.701832Z",
     "start_time": "2018-08-13T20:26:42.697766Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "start_token = \" \"  # so that the network knows that we're generating a first token\n",
    "\n",
    "# this is the token for padding,\n",
    "# we will add fake pad token at the end of names \n",
    "# to make them of equal size for further batching\n",
    "pad_token = \"#\"\n",
    "\n",
    "with open(\"names\") as f:\n",
    "    names = f.read()[:-1].split('\\n')\n",
    "    names = [start_token + name for name in names]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-08-13T20:26:42.707885Z",
     "start_time": "2018-08-13T20:26:42.703302Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of samples: 7944\n",
      " Abagael\n",
      " Claresta\n",
      " Glory\n",
      " Liliane\n",
      " Prissie\n",
      " Geeta\n",
      " Giovanne\n",
      " Piggy\n"
     ]
    }
   ],
   "source": [
    "print('number of samples:', len(names))\n",
    "for x in names[::1000]:\n",
    "    print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-08-13T20:26:42.857411Z",
     "start_time": "2018-08-13T20:26:42.709371Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "max length: 16\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYEAAAEICAYAAAC55kg0AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nLgJmZhlzETAzy9j/B8WHKERRkkO/AAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7fa86805b160>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "MAX_LENGTH = max(map(len, names))\n",
    "print(\"max length:\", MAX_LENGTH)\n",
    "\n",
    "plt.title('Sequence length distribution')\n",
    "plt.hist(list(map(len, names)), bins=25);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Text processing\n",
    "\n",
    "First we need to collect a \"vocabulary\" of all unique tokens i.e. unique characters. We can then encode inputs as a sequence of character ids."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-08-13T20:26:42.864592Z",
     "start_time": "2018-08-13T20:26:42.858725Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "n_tokens: 55\n"
     ]
    }
   ],
   "source": [
    "tokens = set(''.join(names[:]))\n",
    "#print(tokens)\n",
    "tokens = list(tokens)\n",
    "n_tokens = len(tokens)\n",
    "print ('n_tokens:', n_tokens)\n",
    "\n",
    "assert 50 < n_tokens < 60"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cast everything from symbols into identifiers\n",
    "\n",
    "Tensorflow string manipulation is a bit tricky, so we'll work around it. \n",
    "We'll feed our recurrent neural network with ids of characters from our dictionary.\n",
    "\n",
    "To create such dictionary, let's assign `token_to_id`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-08-13T20:26:42.870330Z",
     "start_time": "2018-08-13T20:26:42.866135Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'F': 0, 'a': 1, 'M': 2, 'E': 3, 'y': 4, 'm': 5, 'v': 6, 'k': 7, 'U': 8, 'O': 9, 'b': 10, 'u': 11, 'Q': 12, 'W': 13, ' ': 14, 'D': 15, 'q': 16, 'K': 17, 'x': 18, 'g': 19, 'd': 20, 'i': 21, 's': 22, 'B': 23, 'S': 24, \"'\": 25, 'P': 26, 'G': 27, 't': 28, 'H': 29, 'T': 30, 'n': 31, 'z': 32, '-': 33, 'J': 34, 'L': 35, 'X': 36, 'h': 37, 'f': 38, 'I': 39, 'A': 40, 'w': 41, 'Z': 42, 'R': 43, 'C': 44, 'o': 45, 'e': 46, 'c': 47, 'j': 48, 'N': 49, 'Y': 50, 'V': 51, 'l': 52, 'r': 53, 'p': 54}\n"
     ]
    }
   ],
   "source": [
    "token_to_id = dict((key, value) for value, key in enumerate(tokens))\n",
    "#print(token_to_id)\n",
    "\n",
    "assert len(tokens) == len(token_to_id), \"dictionaries must have same size\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-08-13T20:26:42.875943Z",
     "start_time": "2018-08-13T20:26:42.871834Z"
    }
   },
   "outputs": [],
   "source": [
    "def to_matrix(names, max_len=None, pad=0, dtype=np.int32):\n",
    "    \"\"\"Casts a list of names into rnn-digestable padded matrix\"\"\"\n",
    "    \n",
    "    max_len = max_len or max(map(len, names))\n",
    "    names_ix = np.zeros([len(names), max_len], dtype) + pad\n",
    "\n",
    "    for i in range(len(names)):\n",
    "        name_ix = list(map(token_to_id.get, names[i]))\n",
    "        names_ix[i, :len(name_ix)] = name_ix\n",
    "\n",
    "    return names_ix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-08-13T20:26:42.883107Z",
     "start_time": "2018-08-13T20:26:42.877186Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Abagael\n",
      " Glory\n",
      " Prissie\n",
      " Giovanne\n",
      "[[14 40 10  1 19  1 46 52  0]\n",
      " [14 27 52 45 53  4  0  0  0]\n",
      " [14 26 53 21 22 22 21 46  0]\n",
      " [14 27 21 45  6  1 31 31 46]]\n"
     ]
    }
   ],
   "source": [
    "# Example: cast 4 random names to padded matrices (so that we can easily batch them)\n",
    "print('\\n'.join(names[::2000]))\n",
    "print(to_matrix(names[::2000]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Defining a recurrent neural network\n",
    "\n",
    "We can rewrite recurrent neural network as a consecutive application of dense layer to input $x_t$ and previous rnn state $h_t$. This is exactly what we're gonna do now.\n",
    "<img src=\"./rnn.png\" width=600>\n",
    "\n",
    "Since we're training a language model, there should also be:\n",
    "* An embedding layer that converts character id x_t to a vector.\n",
    "* An output layer that predicts probabilities of next phoneme based on h_t+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-08-13T20:26:44.039419Z",
     "start_time": "2018-08-13T20:26:42.884581Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# remember to reset your session if you change your graph!\n",
    "s = keras_utils.reset_tf_session()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-08-13T20:26:44.044903Z",
     "start_time": "2018-08-13T20:26:44.041084Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import keras\n",
    "from keras.layers import concatenate, Dense, Embedding\n",
    "\n",
    "rnn_num_units = 64  # size of hidden state\n",
    "embedding_size = 16  # for characters\n",
    "\n",
    "# Let's create layers for our recurrent network\n",
    "# Note: we create layers but we don't \"apply\" them yet (this is a \"functional API\" of Keras)\n",
    "# Note: set the correct activation (from keras.activations) to Dense layers!\n",
    "\n",
    "# an embedding layer that converts character ids into embeddings\n",
    "embed_x = Embedding(n_tokens, embedding_size)\n",
    "\n",
    "# a dense layer that maps input and previous state to new hidden state, [x_t,h_t]->h_t+1\n",
    "get_h_next = Dense(units=rnn_num_units, activation=\"relu\")\n",
    "\n",
    "# a dense layer that maps current hidden state to probabilities of characters [h_t+1]->P(x_t+1|h_t+1)\n",
    "get_probas = Dense(units=n_tokens, activation=\"softmax\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will generate names character by character starting with `start_token`:\n",
    "\n",
    "<img src=\"./char-nn.png\" width=600>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-08-13T20:26:44.053212Z",
     "start_time": "2018-08-13T20:26:44.048389Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def rnn_one_step(x_t, h_t):\n",
    "    \"\"\"\n",
    "    Recurrent neural network step that produces \n",
    "    probabilities for next token x_t+1 and next state h_t+1\n",
    "    given current input x_t and previous state h_t.\n",
    "    We'll call this method repeatedly to produce the whole sequence.\n",
    "    \n",
    "    You're supposed to \"apply\" above layers to produce new tensors.\n",
    "    Follow inline instructions to complete the function.\n",
    "    \"\"\"\n",
    "    # convert character id into embedding\n",
    "    x_t_emb = embed_x(tf.reshape(x_t, [-1, 1]))[:, 0]\n",
    "    \n",
    "    # concatenate x_t embedding and previous h_t state\n",
    "    x_and_h = concatenate([x_t_emb, h_t])\n",
    "    \n",
    "    # compute next state given x_and_h\n",
    "    h_next = get_h_next(x_and_h)\n",
    "    \n",
    "    # get probabilities for language model P(x_next|h_next)\n",
    "    output_probas = get_probas(h_next)\n",
    "    \n",
    "    return output_probas, h_next"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RNN: loop\n",
    "\n",
    "Once `rnn_one_step` is ready, let's apply it in a loop over name characters to get predictions.\n",
    "\n",
    "Let's assume that all names are at most length-16 for now, so we can simply iterate over them in a for loop.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-08-13T20:26:44.342948Z",
     "start_time": "2018-08-13T20:26:44.056136Z"
    }
   },
   "outputs": [],
   "source": [
    "input_sequence = tf.placeholder(tf.int32, (None, MAX_LENGTH))  # batch of token ids\n",
    "batch_size = tf.shape(input_sequence)[0]\n",
    "\n",
    "predicted_probas = []\n",
    "h_prev = tf.zeros([batch_size, rnn_num_units])  # initial hidden state\n",
    "\n",
    "for t in range(MAX_LENGTH):\n",
    "    x_t = input_sequence[:, t]  # column t\n",
    "    probas_next, h_next = rnn_one_step(x_t, h_prev)\n",
    "    \n",
    "    h_prev = h_next\n",
    "    predicted_probas.append(probas_next)\n",
    "    \n",
    "# combine predicted_probas into [batch, time, n_tokens] tensor\n",
    "predicted_probas = tf.transpose(tf.stack(predicted_probas), [1, 0, 2])\n",
    "\n",
    "# next to last token prediction is not needed\n",
    "predicted_probas = predicted_probas[:, :-1, :]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RNN: loss and gradients\n",
    "\n",
    "Let's gather a matrix of predictions for $P(x_{next}|h)$ and the corresponding correct answers.\n",
    "\n",
    "We will flatten our matrices to shape [None, n_tokens] to make it easier.\n",
    "\n",
    "Our network can then be trained by minimizing crossentropy between predicted probabilities and those answers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-08-13T20:26:44.354310Z",
     "start_time": "2018-08-13T20:26:44.344648Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# flatten predictions to [batch*time, n_tokens]\n",
    "predictions_matrix = tf.reshape(predicted_probas, [-1, n_tokens])\n",
    "\n",
    "# flatten answers (next tokens) and one-hot encode them\n",
    "answers_matrix = tf.one_hot(tf.reshape(input_sequence[:, 1:], [-1]), n_tokens)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Usually it's a good idea to ignore gradients of loss for padding token predictions.\n",
    "\n",
    "Because we don't care about further prediction after the pad_token is predicted for the first time, so it doesn't make sense to punish our network after the pad_token is predicted.\n",
    "\n",
    "For simplicity you can ignore this comment, it's up to you."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-08-13T20:26:45.076642Z",
     "start_time": "2018-08-13T20:26:44.355594Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Define the loss as categorical cross-entropy (e.g. from keras.losses).\n",
    "# Mind that predictions are probabilities and NOT logits!\n",
    "# Remember to apply tf.reduce_mean to get a scalar loss!\n",
    "loss = tf.reduce_mean(keras.losses.categorical_crossentropy(answers_matrix, predictions_matrix))\n",
    "\n",
    "optimize = tf.train.AdamOptimizer().minimize(loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RNN: training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-08-13T20:26:55.322187Z",
     "start_time": "2018-08-13T20:26:45.078296Z"
    }
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXcAAAD8CAYAAACMwORRAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nlHKh/w9VeKcNTWyQCgAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7fa82c795c88>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from IPython.display import clear_output\n",
    "from random import sample\n",
    "\n",
    "s.run(tf.global_variables_initializer())\n",
    "\n",
    "batch_size = 32\n",
    "history = []\n",
    "\n",
    "for i in range(1000):\n",
    "    batch = to_matrix(sample(names, batch_size), max_len=MAX_LENGTH)\n",
    "    loss_i, _ = s.run([loss, optimize], {input_sequence: batch})\n",
    "    \n",
    "    history.append(loss_i)\n",
    "    \n",
    "    if (i + 1) % 100 == 0:\n",
    "        clear_output(True)\n",
    "        plt.plot(history, label='loss')\n",
    "        plt.legend()\n",
    "        plt.show()\n",
    "\n",
    "assert np.mean(history[:10]) > np.mean(history[-10:]), \"RNN didn't converge\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RNN: sampling\n",
    "Once we've trained our network a bit, let's get to actually generating stuff. All we need is the `rnn_one_step` function you have written above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-08-13T20:26:55.341196Z",
     "start_time": "2018-08-13T20:26:55.323787Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "x_t = tf.placeholder(tf.int32, (1,))\n",
    "h_t = tf.Variable(np.zeros([1, rnn_num_units], np.float32))  # we will update hidden state in this variable\n",
    "\n",
    "# For sampling we need to define `rnn_one_step` tensors only once in our graph.\n",
    "# We reuse all parameters thanks to functional API usage.\n",
    "# Then we can feed appropriate tensor values using feed_dict in a loop.\n",
    "# Note how different it is from training stage, where we had to unroll the whole sequence for backprop.\n",
    "next_probs, next_h = rnn_one_step(x_t, h_t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-08-13T20:26:55.346422Z",
     "start_time": "2018-08-13T20:26:55.342659Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def generate_sample(seed_phrase=start_token, max_length=MAX_LENGTH):\n",
    "    '''\n",
    "    This function generates text given a `seed_phrase` as a seed.\n",
    "    Remember to include start_token in seed phrase!\n",
    "    Parameter `max_length` is used to set the number of characters in prediction.\n",
    "    '''\n",
    "    x_sequence = [token_to_id[token] for token in seed_phrase]\n",
    "    s.run(tf.assign(h_t, h_t.initial_value))\n",
    "    \n",
    "    # feed the seed phrase, if any\n",
    "    for ix in x_sequence[:-1]:\n",
    "         s.run(tf.assign(h_t, next_h), {x_t: [ix]})\n",
    "    \n",
    "    # start generating\n",
    "    for _ in range(max_length-len(seed_phrase)):\n",
    "        x_probs,_ = s.run([next_probs, tf.assign(h_t, next_h)], {x_t: [x_sequence[-1]]})\n",
    "        x_sequence.append(np.random.choice(n_tokens, p=x_probs[0]))\n",
    "        \n",
    "    return ''.join([tokens[ix] for ix in x_sequence if tokens[ix] != pad_token])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-08-13T20:26:58.458115Z",
     "start_time": "2018-08-13T20:26:55.347900Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " FFrinFFFFFFFFFF\n",
      " JaganFFFFFFFFFF\n",
      " RyfFFFFFFFFFFFF\n",
      " ElticiteFFFFFFF\n",
      " LardinleFFFFFFF\n",
      " JadlernnFFFFFFF\n",
      " MabejlteFFFFFFF\n",
      " BntulaFFFFFFFFF\n",
      " MebyFFFFFFFFFFF\n",
      " KinrronFFFFFFFF\n"
     ]
    }
   ],
   "source": [
    "# without prefix\n",
    "for _ in range(10):\n",
    "    print(generate_sample())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-08-13T20:27:01.986726Z",
     "start_time": "2018-08-13T20:26:58.459810Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " TrumponaFFFFFFF\n",
      " TrumpanceFFFFFF\n",
      " TrumpFFFFFFFFFF\n",
      " TrumpaFFFFFFFFF\n",
      " TrumpesFFFFFFFF\n",
      " TrumpFFFFFFFFFF\n",
      " TrumpaFFFFFFFFF\n",
      " TrumpennoFFFFFF\n",
      " TrumpamFFFFFFFF\n",
      " TrumpennFFFFFFF\n"
     ]
    }
   ],
   "source": [
    "# with prefix conditioning\n",
    "for _ in range(10):\n",
    "    print(generate_sample(' Trump'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Submit to Coursera"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-08-13T20:40:02.004926Z",
     "start_time": "2018-08-13T20:40:02.000821Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# token expires every 30 min\n",
    "COURSERA_TOKEN = \"SOvgQ23Ln1GSqS7w\"\n",
    "COURSERA_EMAIL = \"aditya78624@gmail.com\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-08-13T20:40:18.923357Z",
     "start_time": "2018-08-13T20:40:03.549343Z"
    }
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "860291dda4484024aa123f0c3ed27d68",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "A Jupyter Widget"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Submitted to Coursera platform. See results on assignment page!\n"
     ]
    }
   ],
   "source": [
    "from submit import submit_char_rnn\n",
    "samples = [generate_sample(' Al') for i in tqdm_utils.tqdm_notebook_failsafe(range(25))]\n",
    "submission = (history, samples)\n",
    "submit_char_rnn(submission, COURSERA_EMAIL, COURSERA_TOKEN)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Try it out!\n",
    "\n",
    "__Disclaimer:__ This part of assignment is entirely optional. You won't receive bonus points for it. However, it's a fun thing to do. Please share your results on course forums.\n",
    "\n",
    "You've just implemented a recurrent language model that can be tasked with generating any kind of sequence, so there's plenty of data you can try it on:\n",
    "\n",
    "* Novels/poems/songs of your favorite author\n",
    "* News titles/clickbait titles\n",
    "* Source code of Linux or Tensorflow\n",
    "* Molecules in [smiles](https://en.wikipedia.org/wiki/Simplified_molecular-input_line-entry_system) format\n",
    "* Melody in notes/chords format\n",
    "* IKEA catalog titles\n",
    "* Pokemon names\n",
    "* Cards from Magic, the Gathering / Hearthstone\n",
    "\n",
    "If you're willing to give it a try, here's what you wanna look at:\n",
    "* Current data format is a sequence of lines, so a novel can be formatted as a list of sentences. Alternatively, you can change data preprocessing altogether.\n",
    "* While some datasets are readily available, others can only be scraped from the web. Try `Selenium` or `Scrapy` for that.\n",
    "* Make sure MAX_LENGTH is adjusted for longer datasets. There's also a bonus section about dynamic RNNs at the bottom.\n",
    "* More complex tasks require larger RNN architecture, try more neurons or several layers. It would also require more training iterations.\n",
    "* Long-term dependencies in music, novels or molecules are better handled with LSTM or GRU\n",
    "\n",
    "__Good hunting!__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Bonus level: dynamic RNNs\n",
    "\n",
    "Apart from Keras, there's also a friendly TensorFlow API for recurrent neural nets. It's based around the symbolic loop function (aka [tf.scan](https://www.tensorflow.org/api_docs/python/tf/scan)).\n",
    "\n",
    "RNN loop that we implemented for training can be replaced with single TensorFlow instruction: [tf.nn.dynamic_rnn](https://www.tensorflow.org/api_docs/python/tf/nn/dynamic_rnn).\n",
    "This interface allows for dynamic sequence length and comes with some pre-implemented architectures.\n",
    "\n",
    "Take a look at [tf.nn.rnn_cell.BasicRNNCell](https://www.tensorflow.org/api_docs/python/tf/contrib/rnn/BasicRNNCell)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-08-13T20:27:12.975354Z",
     "start_time": "2018-08-13T20:27:12.737529Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LSTM outputs for each step [batch,time,n_tokens]:\n",
      "(10, 50, 55)\n"
     ]
    }
   ],
   "source": [
    "class CustomRNN(tf.nn.rnn_cell.BasicRNNCell):\n",
    "    def call(self, input, state):\n",
    "        # from docs:\n",
    "        # Returns:\n",
    "        # Output: A 2-D tensor with shape [batch_size, self.output_size].\n",
    "        # New state: Either a single 2-D tensor, or a tuple of tensors matching the arity and shapes of state.\n",
    "        return rnn_one_step(input[:, 0], state)\n",
    "    \n",
    "    @property\n",
    "    def output_size(self):\n",
    "        return n_tokens\n",
    "    \n",
    "cell = CustomRNN(rnn_num_units)\n",
    "\n",
    "input_sequence = tf.placeholder(tf.int32, (None, None))\n",
    "    \n",
    "predicted_probas, last_state = tf.nn.dynamic_rnn(cell, input_sequence[:, :, None], dtype=tf.float32)\n",
    "\n",
    "print('LSTM outputs for each step [batch,time,n_tokens]:')\n",
    "print(predicted_probas.eval({input_sequence: to_matrix(names[:10], max_len=50)}).shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that we never used MAX_LENGTH in the code above: TF will iterate over however many time-steps you gave it.\n",
    "\n",
    "You can also use any pre-implemented RNN cell:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-08-13T20:27:12.981697Z",
     "start_time": "2018-08-13T20:27:12.977590Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BasicLSTMCell\tBasicRNNCell\tGRUCell\tLSTMCell\tMultiRNNCell\tRNNCell\tBasicLSTMCell\tBasicRNNCell\tBidirectionalGridLSTMCell\tCoupledInputForgetGateLSTMCell\tFusedRNNCell\tGLSTMCell\tGRUBlockCell\tGRUCell\tGridLSTMCell\tIntersectionRNNCell\tLSTMBlockCell\tLSTMBlockFusedCell\tLSTMCell\tLayerNormBasicLSTMCell\tMultiRNNCell\tNASCell\tPhasedLSTMCell\tRNNCell\tTimeFreqLSTMCell\tUGRNNCell\t"
     ]
    }
   ],
   "source": [
    "for obj in dir(tf.nn.rnn_cell) + dir(tf.contrib.rnn):\n",
    "    if obj.endswith('Cell'):\n",
    "        print(obj, end=\"\\t\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-08-13T20:27:13.168207Z",
     "start_time": "2018-08-13T20:27:12.986884Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LSTM hidden state for each step [batch,time,rnn_num_units]:\n",
      "(10, 50, 64)\n"
     ]
    }
   ],
   "source": [
    "input_sequence = tf.placeholder(tf.int32, (None, None))\n",
    "\n",
    "inputs_embedded = embed_x(input_sequence)\n",
    "\n",
    "# standard cell returns hidden state as output!\n",
    "cell = tf.nn.rnn_cell.LSTMCell(rnn_num_units)\n",
    "\n",
    "state_sequence, last_state = tf.nn.dynamic_rnn(cell, inputs_embedded, dtype=tf.float32)\n",
    "\n",
    "s.run(tf.global_variables_initializer())\n",
    "\n",
    "print('LSTM hidden state for each step [batch,time,rnn_num_units]:')\n",
    "print(state_sequence.eval({input_sequence: to_matrix(names[:10], max_len=50)}).shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
